{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Path to the web driver executable (e.g., chromedriver)\n",
    "linkedin_profile = 'https://www.linkedin.com/in/antonio-castaldo/'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "\n",
    "# Create a browser instance\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Open the LinkedIn profile page\n",
    "driver.get(linkedin_profile)\n",
    "\n",
    "# Extract the page source or perform other actions with the browser\n",
    "source = driver.page_source\n",
    "\n",
    "with open('linkedin_profile.html', 'w') as f:\n",
    "    f.write(source)\n",
    "    \n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(source, \"html.parser\")\n",
    "with open('linkedin_profile.html', 'w') as f:\n",
    "    f.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "certificates_list = soup.find(\"section\", class_=\"core-section-container my-3 core-section-container--with-border border-b-1 border-solid border-color-border-faint m-0 py-3 pp-section certifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Le Wagon - Data Science Bootcamp from Le Wagon (Issued Jun 2023)', '\"L\\'Orientale\" Apple Foundation Program IX from Apple (Issued Dec 2021)', 'Chinese Language Certificate HSK 3 from Beijing Language and Culture University (Issued Jan 2020)', 'ECDL from ECDL / ICDL Certification (Issued Jan 2012)']\n"
     ]
    }
   ],
   "source": [
    "certification_titles = certificates_list.find_all('h3', class_='profile-section-card__title')\n",
    "certification_titles = [certificate.text.strip() for certificate in certification_titles]\n",
    "\n",
    "certification_universities = certificates_list.find_all('a', class_='profile-section-card__subtitle-link')\n",
    "certification_universities = [certificate.text.strip() for certificate in certification_universities]\n",
    "\n",
    "certification_dates = certificates_list.find_all('div', class_='profile-section-card__meta')\n",
    "certification_dates = [certificate.text.strip() for certificate in certification_dates]\n",
    "certification_dates = [certificate.split('\\n')[0].strip() for certificate in certification_dates if certificate != '']\n",
    "\n",
    "merged_certifications = list(zip(certification_titles, certification_universities, certification_dates))\n",
    "textified_certifications = [f\"{title} from {university} ({date})\" for title, university, date in merged_certifications]\n",
    "\n",
    "print(textified_certifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Le Wagon (2023 - 2023) characterized by the following description: \\nLe Wagon Brussels in Data Science (Batch #1239).9-week full-time intensive Data Science bootcamp with Python: - Data Analytics with SQL, BigQuery, Pandas, Numpy and Matplotlib; - Statistics with Scipy, Seaborn and Statsmodels;- Machine Learning with Scikit-learn; - Deep Learning with TensorFlow Keras;- Data Products Development with Google Cloud Platform, ML Flow, Flask, Heroku and Streamlit.My GitHub URL: https://github.com/Ancastal', \"Università di Napoli L'Orientale (2020 - 2023) characterized by the following description: \\nDissertation title “Evaluating the Effectiveness of Machine Translation for Literary Works: A comparative study of English and Chinese corpora”. Principal subjects and occupational skills covered:• Comparative languages and cultures (English and Chinese).• Machine translation.• Translation studies.• English linguistics.• Chinese linguistics.• Computational linguistics.• General and historical linguistics.\", 'Università degli Studi di Napoli \"L\\'Orientale\" (2016 - 2019) characterized by the following description: \\nPrincipal subjects covered:• Comparative languages and cultures (Japanese and English).• English Advanced Proficiency (C2 CEFR)• HSK 3/4 Proficiency in Chinese• B1/B2 French proficiency certification• Teaching methods• General linguistics• Philology• English and Chinese literatures', 'Université libre de Bruxelles (2018 - 2019) characterized by the following description: \\nI was awarded an Erasmus+ scholarship, to attend an exchange program at the Université Libre de Bruxelles for an academic year (9 months).Principal subjects covered:• Comparative languages and cultures (Chinese and English).• English for Technical Purposes• Analysis and Criticism of Literary Works', '北京语言大学 Beijing Language and Culture University (2018 - 2018) characterized by the following description: \\nI have attended an intensive Chinese language program at the Beijing Language and Culture University, where I have mastered Chinese communication, writing and reading skills. At the end of the course, I was awarded with the HSK Certification Level 3.']\n"
     ]
    }
   ],
   "source": [
    "education_list = soup.find(\"section\", class_=\"core-section-container my-3 core-section-container--with-border border-b-1 border-solid border-color-border-faint m-0 py-3 pp-section education\")\n",
    "education_titles = education_list.find_all('h3', class_='profile-section-card__title')\n",
    "education_titles = [education.text.strip() for education in education_titles]\n",
    "\n",
    "education_dates = education_list.find_all('div', class_='profile-section-card__meta')\n",
    "education_dates = [education.text.strip() for education in education_dates]\n",
    "education_dates = [education.split('\\n')[0].strip() for education in education_dates if education != '']\n",
    "\n",
    "education_descriptions = education_list.find_all('div', class_='education__item--details')\n",
    "education_descriptions = [education.text.strip() for education in education_descriptions]\n",
    "\n",
    "merged_educations = list(zip(education_titles, education_dates, education_descriptions))\n",
    "textified_educations = [f\"{title} ({date}) characterized by the following description: \\n{description}\" for title, date, description in merged_educations]\n",
    "\n",
    "print(textified_educations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java Developer at Fiverr characterized by the following description: \\n• Developed Minecraft plugins in Java, using Bukkit and Spigot API.• Implemented features such as custom game mechanics and economy systems.• Collaborated with a team of developers to ensure plugin compatibility.']\n"
     ]
    }
   ],
   "source": [
    "jobs_list = soup.find(\"section\", class_=\"core-section-container my-3 core-section-container--with-border border-b-1 border-solid border-color-border-faint m-0 py-3 pp-section experience\")\n",
    "jobs_titles = jobs_list.find_all('h3', class_='profile-section-card__title')\n",
    "jobs_titles = [job.text.strip() for job in jobs_titles]\n",
    "\n",
    "jobs_companies = jobs_list.find_all('a', class_='profile-section-card__subtitle-link')\n",
    "jobs_companies = [job.text.strip() for job in jobs_companies]\n",
    "\n",
    "jobs_descriptions = jobs_list.find_all('div', class_='experience-item__description experience-item__meta-item')\n",
    "jobs_descriptions = [job.text.strip() for job in jobs_descriptions]\n",
    "\n",
    "merged_jobs = list(zip(jobs_titles, jobs_companies, jobs_descriptions))\n",
    "textified_jobs = [f\"{title} at {company} characterized by the following description: \\n{description}\" for title, company, description in merged_jobs]\n",
    "print(textified_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
